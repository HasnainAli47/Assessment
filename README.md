# HEAL-Summ-Lite

A local health-article summarization tool with built-in quality checks, risk scoring, and a human-review escalation rule.

## Setup

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm


# pull the model (Ollama must be installed)
ollama pull gemma3:4b

# start the server
uvicorn app:app --reload --port 8000
```

Open http://localhost:8000, drop `.txt` articles into `data/raw_articles/`, hit *Process articles*.

## How it works

The pipeline has four stages:

1. **Summarise** — Ollama (`gemma3:4b`) generates a summary whose length scales with the input: the target is 30-50% of the article's word count, clamped to a 25-word floor and 200-word ceiling. A 60-word article gets a ~25-30 word summary; a 500-word article gets ~150-200 words. If the word count is off, the system retries up to twice with a stricter prompt. Non-medical text is blocked by a keyword gate before it ever reaches the model.

2. **Evaluate** — Five independent checks run on every summary:
   - *Readability* (Flesch-Kincaid grade level + reading ease via textstat)
   - *Entity coverage* — what fraction of the original's key entities (people, orgs, dates, numbers) survived into the summary
   - *Hallucination detection* — entities that appear in the summary but not in the source
   - *Numeric consistency* — whether the summary preserved the original statistics
   - *ROUGE scores* — optional, only computed when a hand-written reference summary is available

3. **Score risk** — Six binary flags (missing numbers, low coverage, hard readability, hallucination, toxicity, length violation) are tallied. 0 = Low, 1 = Medium, 2+ = High.

4. **Escalate or pass** — A summary is sent for human review if *any* of these hold: risk is High, entity coverage < 50%, word count is out of range, hallucination detected, or FKGL > 12.

## Why these thresholds

- **FKGL 10 / 12**: The CDC recommends health materials at an 8th-grade level. 10 flags it, 12 forces escalation.
- **Entity coverage 0.6 / 0.5**: Below 60% the summary typically drops something important. Below 50% it's unreliable.
- **Dynamic summary length (30-50% ratio)**: The target word count scales with the input. A fixed 120-word target would force expansion on short articles and under-compress long ones. The 30-50% ratio keeps the summary proportional. Floor of 25 words prevents useless one-liners; ceiling of 200 keeps it readable.

## Known issues

- The model sometimes **drops exact statistics** — e.g. rounding "89.3%" to "approximately 90%". The numeric checker flags this.
- It can **hallucinate entire facts** when input is vague or short. We saw it invent AMI trial data from Lorem Ipsum text. The hallucination flag + keyword gate mitigate this, but the underlying LLM behaviour remains.
- **Entity coverage uses substring matching**, so "North" matches inside "North America". Lemmatisation or fuzzy matching would be better.
- **Numeric regex** misses written-out numbers ("two million"), ranges ("5-10%"), and comma-separated formats ("1,850").
- Entity coverage and hallucination detection are complementary — high coverage does not mean the summary is free of fabricated content.

## Project layout

```
heal_summ_lite/
├── app.py            # FastAPI server + embedded UI
├── summarizer.py     # Ollama calls, retry logic, input validation
├── evaluator.py      # readability, NER, coverage, hallucination, ROUGE
├── risk.py           # flag counting, risk levels, escalation rules
├── utils.py          # shared helpers
├── config.py         # all tuneable constants
├── data/raw_articles/  # input .txt files go here
├── results/            # output JSON + CSV
├── tests/              # pytest suite
├── requirements.txt
└── README.md
```

## Tests

```bash
pytest tests/ -v
```

## Tools used

| Tool | Purpose |
|---|---|
| Ollama (gemma3:4b) | Summary generation (local LLM) |
| spaCy (en_core_web_sm) | Named-entity recognition |
| scispaCy (en_core_sci_sm) | Biomedical NER (optional) |
| textstat | Readability scoring |
| rouge-score | Evaluation metric |
| FastAPI + uvicorn | Web server |

Summaries are generated by an LLM. All validation, scoring, and escalation logic is deterministic code written by the developer.

- **Approach:** Used a local LLM (Ollama, gemma3:4b) for summary generation paired with a deterministic validation pipeline, readability scoring, NER-based entity coverage, hallucination detection, numeric consistency checks, and rule-based risk scoring. Chose a local model over cloud APIs so all patient/health data stays on-device with zero network exposure.

- **Why this stack:** spaCy gives fast, reliable entity extraction without needing a GPU. textstat is lightweight and well-tested for readability metrics. Keeping the evaluation layer fully rule-based (no ML) means the checks are transparent, reproducible, and easy to explain to a reviewer or auditor.

- **Assumption — input is English health text:** The keyword gate and NER models are English-only. Non-English or non-medical content is rejected before it reaches the LLM. We assume articles are at least 30 words long; anything shorter isn't meaningful enough to summarise.

- **Assumption — dynamic compression is better than fixed targets:** Summary length scales to 30-50% of the input. This avoids the failure case where a short article gets "expanded" into a longer summary, which is really just hallucination dressed up as summarisation.

- **Assumption — thresholds are conservative:** Entity coverage at 0.6, FKGL at 10, escalation at coverage < 0.5 or FKGL > 12. These are intentionally strict for a health context — a false alarm (flagging a good summary) is far less dangerous than a miss (letting a bad one through).

- **What worked:** The hallucination detector caught fabricated entities reliably. When we fed Lorem Ipsum to the system, it generated a fake clinical trial summary — but the detector flagged every invented entity and escalated immediately. The numeric consistency checker also reliably catches when the model rounds or drops statistics.

- **What didn't work (failure case):** Small models (4B parameters) frequently drop exact numbers from summaries — replacing "89.3%" with "roughly 90%" or omitting specific figures entirely. The retry mechanism helps but doesn't fully solve this. Also the model generates the summary with high FKGL score higher and also mostly hallucinates.

- **Evaluation metric used:** Entity coverage ratio — we extract named entities (people, organisations, dates, percentages, quantities) from both the original and summary using spaCy NER, then compute the fraction of original entities preserved. This directly measures factual completeness. We also compute Flesch-Kincaid Grade Level to ensure the summary is accessible to a general audience.

- **Human-review rule:** Any summary with hallucinated entities, entity coverage below 50%, FKGL above 12, or word count outside the dynamic target range is automatically escalated for human review. This ensures no high-risk summary reaches an end user without a human sign-off.

- **Future improvements:** Fine-tune on medical summarisation corpora (PubMed abstracts), add scispaCy entity linking to UMLS concepts for research-grade NER, implement confidence scoring per sentence so partial summaries can be accepted, and integrate detoxify for active toxicity detection. Also we can put some guardrails using LLM to evaluate the summary again. We can use techniques like masking technique to use external API for better output.
